import os
import warnings
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
import tensorflow.keras.utils as utils
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, ZeroPadding2D
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.utils import plot_model
from tensorflow.keras.callbacks import ModelCheckpoint
from pathlib import Path
from tensorflow.keras import models, layers, optimizers
from sklearn.utils.class_weight import compute_class_weight
from google.colab import drive
drive.mount('/content/drive')
data_path = '/content/drive/MyDrive/GARBAGE DATASET/Train'
#\Data Classes
print(os.listdir(data_path))
main_folder_path = Path(data_path)
all_folders = [d for d in main_folder_path.glob('**/') if d.is_dir()]
# Count number of files in each class
data = []
for folder in all_folders:
folder_name = folder.name
file_count = len(list(folder.glob('*.*')))
if folder_name != data_path:
data.append({'Folder Name': folder_name, 'File Count': file_count})
count = pd.DataFrame(data)
count = count.set_index('Folder Name')
count
Train 0
PAPER 264
CLOTHES 125
PLASTIC 434
GLASS 177
METAL 110
print(f'Total {count.sum()}')
# Show five image of each class
def plot_imgs(item_dir, top=10):
all_item_dirs = os.listdir(item_dir)
item_files = [os.path.join(item_dir, file) for file in all_item_dirs][:5]
plt.figure(figsize=(10, 10))
for idx, img_path in enumerate(item_files):
plt.subplot(5, 5, idx+1)
img = plt.imread(img_path)
plt.tight_layout()
plt.imshow(img, cmap='gray')
plt.axis('off')
plt.title(os.path.basename(item_dir))
plot_imgs(data_path+'/CLOTHES')
plot_imgs(data_path+'/PLASTIC')
plot_imgs(data_path+'/METAL')
plot_imgs(data_path+'/GLASS')
plot_imgs(data_path+'/PAPER
